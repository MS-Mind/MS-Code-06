# Architecture
arch: dm_nfnet_f0

# ===== Dataset ===== #
data_url: ./data/imagenet
set: ImageNet
num_classes: 1000
mix_up: 0.8
cutmix: 1.0
auto_augment: rand-m5-n4-mstd0.5-inc1
interpolation: bicubic
re_prob: 0.
re_mode: pixel
re_count: 1
mixup_prob: 1.
switch_prob: 0.5
mixup_mode: batch


# ===== Learning Rate Policy ======== #
accumulation_step: 1
base_lr: 0.1
clipping: 0.01
lr_scheduler: cosine_lr
min_lr: 0.0000006
use_nesterov: True
optimizer: SGDAGC
warmup_length: 5
warmup_lr: 0.0000007

# ===== Network training config ===== #
amp_level: O2
batch_size: 256
epochs: 360
eps: 0.001
eval_while_train: False
is_dynamic_loss_scale: True
label_smoothing: 0.1
loss_scale: 1024
momentum: 0.9
weight_decay: 0.00002

# ===== Hardware setup ===== #
num_parallel_workers: 16
device_target: Ascend

# ===== Model config ===== #
input_size: 192
test_input_size: 256
crop_pct: 30
depths: [ 1, 2, 6, 3 ]
drop_rate: 0.2
drop_path_rate: 0.25